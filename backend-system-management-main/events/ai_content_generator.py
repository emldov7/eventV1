"""
ü§ñ G√âN√âRATEUR DE CONTENU IA AVANC√â
Utilise de vrais mod√®les IA (Mistral/Claude) et s'int√®gre avec le syst√®me de pr√©diction
"""

import logging
import os
from typing import Dict, List, Optional
from django.conf import settings
import anthropic
try:
    from mistralai.client import MistralClient
    from mistralai.models.chat_completion import ChatMessage
    MISTRAL_AVAILABLE = True
except ImportError:
    MISTRAL_AVAILABLE = False
    MistralClient = None
    ChatMessage = None

logger = logging.getLogger(__name__)

class AIContentGenerator:
    """
    G√©n√©rateur de contenu utilisant de vrais mod√®les IA
    S'int√®gre avec le syst√®me de pr√©diction existant
    """
    
    def __init__(self):
        """Initialise le g√©n√©rateur IA avec les mod√®les disponibles"""
        self.anthropic_client = None
        self.mistral_client = None
        self.openai_client = None
        
        # Initialiser les clients IA selon les cl√©s disponibles
        self._initialize_ai_clients()
        
        # Mod√®le par d√©faut (priorit√© : Mistral > Claude > OpenAI)
        self.default_model = self._get_default_model()
        
    def _initialize_ai_clients(self):
        """Initialise les clients IA selon les cl√©s API disponibles"""
        try:
            # Claude (Anthropic) - Priorit√© 1
            if os.getenv('ANTHROPIC_API_KEY'):
                self.anthropic_client = anthropic.Anthropic(
                    api_key=os.getenv('ANTHROPIC_API_KEY')
                )
                logger.info("‚úÖ Client Claude (Anthropic) initialis√©")
            
            # Mistral AI - Priorit√© 2
            if os.getenv('MISTRAL_API_KEY') and MISTRAL_AVAILABLE:
                try:
                    self.mistral_client = MistralClient(
                        api_key=os.getenv('MISTRAL_API_KEY')
                    )
                    logger.info("‚úÖ Client Mistral AI initialis√©")
                except Exception as e:
                    logger.error(f"‚ùå Erreur initialisation Mistral: {str(e)}")
                    self.mistral_client = None
            elif os.getenv('MISTRAL_API_KEY') and not MISTRAL_AVAILABLE:
                logger.warning("‚ö†Ô∏è Cl√© Mistral configur√©e mais package non install√©")
            
            # OpenAI - Priorit√© 3
            if os.getenv('OPENAI_API_KEY'):
                import openai
                openai.api_key = os.getenv('OPENAI_API_KEY')
                self.openai_client = openai
                logger.info("‚úÖ Client OpenAI initialis√©")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation des clients IA: {str(e)}")
    
    def _get_default_model(self) -> str:
        """D√©termine le mod√®le IA par d√©faut disponible"""
        if self.mistral_client:
            return "mistral"
        elif self.anthropic_client:
            return "claude"
        elif self.openai_client:
            return "openai"
        else:
            return "none"
    
    def generate_event_description(self, title: str, category: str, location: str, 
                                 price: float = 0, max_capacity: int = None,
                                 prediction_data: Dict = None) -> str:
        """
        G√©n√®re une description d'√©v√©nement avec de l'IA
        
        Args:
            title: Titre de l'√©v√©nement
            category: Cat√©gorie de l'√©v√©nement
            location: Lieu de l'√©v√©nement
            price: Prix de l'√©v√©nement
            max_capacity: Capacit√© maximale
            prediction_data: Donn√©es de pr√©diction du syst√®me existant
            
        Returns:
            Description g√©n√©r√©e par l'IA
        """
        try:
            if self.default_model == "none":
                logger.warning("‚ö†Ô∏è Aucun mod√®le IA disponible, utilisation du fallback")
                return self._generate_fallback_description(title, category, location, price, max_capacity)
            
            # Construire le prompt intelligent
            prompt = self._build_smart_prompt(
                title, category, location, price, max_capacity, prediction_data
            )
            
            # G√©n√©rer avec le mod√®le IA
            if self.default_model == "claude":
                return self._generate_with_claude(prompt)
            elif self.default_model == "mistral":
                return self._generate_with_mistral(prompt)
            elif self.default_model == "openai":
                return self._generate_with_openai(prompt)
            else:
                return self._generate_fallback_description(title, category, location, price, max_capacity)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration IA: {str(e)}")
            return self._generate_fallback_description(title, category, location, price, max_capacity)
    
    def generate_hashtags(self, title: str, category: str, description: str = None,
                          prediction_data: Dict = None) -> List[str]:
        """
        G√©n√®re des hashtags optimis√©s avec l'IA
        
        Args:
            title: Titre de l'√©v√©nement
            category: Cat√©gorie de l'√©v√©nement
            description: Description de l'√©v√©nement
            prediction_data: Donn√©es de pr√©diction
            
        Returns:
            Liste de hashtags optimis√©s
        """
        try:
            if self.default_model == "none":
                return self._generate_fallback_hashtags(title, category)
            
            # Construire le prompt pour les hashtags
            hashtag_prompt = self._build_hashtag_prompt(
                title, category, description, prediction_data
            )
            
            # G√©n√©rer avec le mod√®le IA
            if self.default_model == "claude":
                hashtags_text = self._generate_with_claude(hashtag_prompt)
            elif self.default_model == "mistral":
                hashtags_text = self._generate_with_mistral(hashtag_prompt)
            elif self.default_model == "openai":
                hashtags_text = self._generate_with_openai(hashtag_prompt)
            else:
                return self._generate_fallback_hashtags(title, category)
            
            # Parser la r√©ponse de l'IA
            return self._parse_hashtags_response(hashtags_text)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration de hashtags IA: {str(e)}")
            return self._generate_fallback_hashtags(title, category)
    
    def generate_visual_suggestions(self, category: str, title: str, description: str = None,
                                   prediction_data: Dict = None) -> Dict:
        """
        G√©n√®re des suggestions visuelles avec l'IA
        
        Args:
            category: Cat√©gorie de l'√©v√©nement
            title: Titre de l'√©v√©nement
            description: Description de l'√©v√©nement
            prediction_data: Donn√©es de pr√©diction
            
        Returns:
            Suggestions visuelles g√©n√©r√©es par l'IA
        """
        try:
            if self.default_model == "none":
                return self._generate_fallback_visual_suggestions(category)
            
            # Construire le prompt pour les suggestions visuelles
            visual_prompt = self._build_visual_prompt(
                category, title, description, prediction_data
            )
            
            # G√©n√©rer avec le mod√®le IA
            if self.default_model == "claude":
                visual_text = self._generate_with_claude(visual_prompt)
            elif self.default_model == "mistral":
                visual_text = self._generate_with_mistral(visual_prompt)
            elif self.default_model == "openai":
                visual_text = self._generate_with_openai(visual_prompt)
            else:
                return self._generate_fallback_visual_suggestions(category)
            
            # Parser la r√©ponse de l'IA
            return self._parse_visual_response(visual_text)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration de suggestions visuelles IA: {str(e)}")
            return self._generate_fallback_visual_suggestions(category)
    
    def _build_smart_prompt(self, title: str, category: str, location: str, 
                           price: float, max_capacity: int, prediction_data: Dict = None) -> str:
        """Construit un prompt intelligent pour l'IA"""
        
        # Base du prompt
        prompt = f"""
Tu es un expert en marketing d'√©v√©nements et en copywriting fran√ßais. 
Cr√©e une description captivante et professionnelle pour l'√©v√©nement suivant :

üìã INFORMATIONS DE BASE :
- Titre : {title}
- Cat√©gorie : {category}
- Lieu : {location}
- Prix : {price}‚Ç¨ {'(Gratuit)' if price == 0 else ''}
- Capacit√© : {max_capacity if max_capacity else 'Illimit√©e'} participants

üéØ OBJECTIFS :
- Description engageante et professionnelle
- Optimis√©e pour la conversion (inscriptions)
- Ton adapt√© √† la cat√©gorie {category}
- En fran√ßais naturel et fluide
- Longueur : 150-200 mots
- Structure : Accroche + Contenu + Call-to-action

"""
        
        # Ajouter les donn√©es de pr√©diction si disponibles
        if prediction_data:
            prompt += f"""
üöÄ DONN√âES D'INTELLIGENCE ARTIFICIELLE (de notre syst√®me de pr√©diction) :
- Taux de remplissage pr√©vu : {prediction_data.get('predicted_fill_rate', 'N/A')}%
- Prix optimal recommand√© : {prediction_data.get('optimal_price', 'N/A')}‚Ç¨
- Tendances d√©tect√©es : {prediction_data.get('trends', 'N/A')}
- Recommandations : {prediction_data.get('recommendations', 'N/A')}

Utilise ces insights pour cr√©er une description encore plus persuasive !
"""
        
        prompt += f"""
üí° CONSEILS SP√âCIFIQUES POUR {category.upper()} :
"""
        
        # Conseils sp√©cifiques par cat√©gorie
        category_tips = {
            "Conf√©rence": "Mettez l'accent sur l'expertise, l'apprentissage et le networking professionnel",
            "Concert": "Cr√©ez une ambiance festive, √©voquez les √©motions et l'exp√©rience musicale",
            "Sport": "Soulignez la motivation, le d√©passement de soi et l'√©nergie",
            "Workshop": "Insistez sur l'apprentissage pratique, les comp√©tences acquises et l'interactivit√©",
            "Meetup": "Mettez l'accent sur la communaut√©, le partage et les √©changes"
        }
        
        prompt += category_tips.get(category, "Cr√©ez une description engageante et professionnelle")
        
        prompt += """

üé® STYLE ET TON :
- Professionnel mais accessible
- Utilise des verbes d'action
- Cr√©e de l'urgence et de l'exclusivit√©
- Termine par un call-to-action clair

G√©n√®re maintenant la description en fran√ßais :
"""
        
        return prompt
    
    def _build_hashtag_prompt(self, title: str, category: str, description: str = None,
                              prediction_data: Dict = None) -> str:
        """Construit un prompt pour la g√©n√©ration de hashtags"""
        
        prompt = f"""
Tu es un expert en marketing digital et r√©seaux sociaux.

G√©n√®re 8-10 hashtags optimis√©s pour l'√©v√©nement suivant :

üìã √âV√âNEMENT :
- Titre : {title}
- Cat√©gorie : {category}
- Description : {description[:200] + '...' if description and len(description) > 200 else description or 'Non fournie'}

üéØ OBJECTIFS :
- Hashtags populaires et recherch√©s
- Optimis√©s pour la visibilit√© sur Instagram, LinkedIn, Twitter
- M√©lange de hashtags g√©n√©riques et sp√©cifiques
- Maximum 10 hashtags
- Format : #Hashtag (sans espaces)

üí° EXEMPLES POUR {category} :
- Hashtags de cat√©gorie (#{category}, #√âv√©nement, etc.)
- Hashtags de localisation (#{title.split()[0] if title else 'Ville'})
- Hashtags de tendance (#Innovation, #D√©couverte, etc.)

G√©n√®re maintenant les hashtags (un par ligne, format #Hashtag) :
"""
        
        return prompt
    
    def _build_visual_prompt(self, category: str, title: str, description: str = None,
                             prediction_data: Dict = None) -> str:
        """Construit un prompt pour les suggestions visuelles"""
        
        prompt = f"""
Tu es un expert en design et marketing visuel.

G√©n√®re des suggestions visuelles pour l'√©v√©nement suivant :

üìã √âV√âNEMENT :
- Titre : {title}
- Cat√©gorie : {category}
- Description : {description[:200] + '...' if description and len(description) > 200 else description or 'Non fournie'}

üé® SUGGESTIONS DEMAND√âES :
1. Palette de couleurs (codes hexad√©cimaux)
2. Th√®mes visuels
3. √âl√©ments de design
4. Style recommand√©
5. Recommandations personnalis√©es

üìä FORMAT DE R√âPONSE (JSON) :
{{
    "colors": ["#code1", "#code2", "#code3"],
    "themes": ["th√®me1", "th√®me2", "th√®me3"],
    "elements": ["√©l√©ment1", "√©l√©ment2", "√©l√©ment3"],
    "style": "description du style",
    "recommendations": ["recommandation1", "recommandation2"]
}}

üí° CONSEILS POUR {category.upper()} :
- Adapte les couleurs √† l'ambiance de la cat√©gorie
- Sugg√®re des √©l√©ments visuels coh√©rents
- Donne des recommandations pratiques

G√©n√®re maintenant les suggestions au format JSON :
"""
        
        return prompt
    
    def _generate_with_claude(self, prompt: str) -> str:
        """G√©n√®re du contenu avec Claude (Anthropic)"""
        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1000,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
        except Exception as e:
            logger.error(f"‚ùå Erreur Claude: {str(e)}")
            raise
    
    def _generate_with_mistral(self, prompt: str) -> str:
        """G√©n√®re du contenu avec Mistral AI"""
        try:
            messages = [ChatMessage(role="user", content=prompt)]
            response = self.mistral_client.chat(
                model="mistral-large-latest",
                messages=messages
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"‚ùå Erreur Mistral: {str(e)}")
            raise
    
    def _generate_with_openai(self, prompt: str) -> str:
        """G√©n√®re du contenu avec OpenAI"""
        try:
            response = self.openai_client.ChatCompletion.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"‚ùå Erreur OpenAI: {str(e)}")
            raise
    
    def _parse_hashtags_response(self, response: str) -> List[str]:
        """Parse la r√©ponse de l'IA pour extraire les hashtags"""
        try:
            # Nettoyer la r√©ponse
            lines = response.strip().split('\n')
            hashtags = []
            
            for line in lines:
                line = line.strip()
                if line.startswith('#'):
                    # Nettoyer le hashtag
                    hashtag = line.split()[0]  # Prendre le premier mot
                    if len(hashtag) <= 30:  # Limiter la longueur
                        hashtags.append(hashtag)
                elif '#' in line:
                    # Chercher les hashtags dans la ligne
                    words = line.split()
                    for word in words:
                        if word.startswith('#') and len(word) <= 30:
                            hashtags.append(word)
            
            # Limiter √† 10 hashtags et ajouter des hashtags par d√©faut si n√©cessaire
            if len(hashtags) < 5:
                default_hashtags = ["#√âv√©nement", "#D√©couverte", "#Exp√©rience"]
                hashtags.extend(default_hashtags)
            
            return hashtags[:10]
            
        except Exception as e:
            logger.error(f"‚ùå Erreur parsing hashtags: {str(e)}")
            return ["#√âv√©nement", "#D√©couverte", "#Exp√©rience"]
    
    def _parse_visual_response(self, response: str) -> Dict:
        """Parse la r√©ponse de l'IA pour extraire les suggestions visuelles"""
        try:
            # Essayer de parser le JSON
            import json
            import re
            
            # Chercher du JSON dans la r√©ponse
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    data = json.loads(json_match.group())
                    return {
                        "colors": data.get("colors", ["#1976d2", "#42a5f5"]),
                        "themes": data.get("themes", ["moderne", "professionnel"]),
                        "elements": data.get("elements", ["ic√¥nes", "typographie"]),
                        "style": data.get("style", "moderne et √©l√©gant"),
                        "recommendations": data.get("recommendations", ["Utilisez un design √©pur√©"])
                    }
                except json.JSONDecodeError:
                    pass
            
            # Fallback si pas de JSON valide
            return self._generate_fallback_visual_suggestions("Conf√©rence")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur parsing suggestions visuelles: {str(e)}")
            return self._generate_fallback_visual_suggestions("Conf√©rence")
    
    def _generate_fallback_description(self, title: str, category: str, location: str, 
                                    price: float, max_capacity: int) -> str:
        """G√©n√®re une description de fallback si l'IA n'est pas disponible"""
        return f"Un √©v√©nement passionnant sur {title} √† {location}. Rejoignez-nous pour une exp√©rience unique !"
    
    def _generate_fallback_hashtags(self, title: str, category: str) -> List[str]:
        """G√©n√®re des hashtags de fallback"""
        return ["#√âv√©nement", "#D√©couverte", "#Exp√©rience", "#Incontournable"]
    
    def _generate_fallback_visual_suggestions(self, category: str) -> Dict:
        """G√©n√®re des suggestions visuelles de fallback"""
        return {
            "colors": ["#1976d2", "#42a5f5"],
            "themes": ["moderne", "professionnel"],
            "elements": ["ic√¥nes", "typographie"],
            "style": "moderne et √©l√©gant",
            "recommendations": ["Utilisez un design √©pur√© et professionnel"]
        }

def get_ai_content_generator():
    """Retourne une instance du g√©n√©rateur de contenu IA"""
    return AIContentGenerator()
