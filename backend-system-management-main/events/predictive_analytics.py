"""
üéØ ANALYTICS PR√âDICTIFS AVANC√âS
Service d'intelligence artificielle pour la pr√©diction et l'optimisation des √©v√©nements

Fonctionnalit√©s :
- Pr√©diction du taux de remplissage des √©v√©nements
- Optimisation des prix bas√©e sur l'analyse du march√©
- D√©tection des tendances √©mergentes
"""

import logging
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from django.db.models import Q, Count, Avg, Sum, F, Min, Max, StdDev
from django.utils import timezone
from django.conf import settings
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score
import joblib
import os
import json

logger = logging.getLogger(__name__)

class PredictiveAnalyticsService:
    """
    Service d'analytics pr√©dictifs utilisant le machine learning
    pour optimiser la gestion des √©v√©nements
    """
    
    def __init__(self):
        self.models_dir = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        
    def ensure_models_directory(self):
        """Cr√©e le r√©pertoire pour sauvegarder les mod√®les ML"""
        if self.models_dir is None:
            from django.conf import settings
            self.models_dir = os.path.join(settings.BASE_DIR, 'ml_models')
        
        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
    
    def prepare_event_features(self, event_data: List[Dict]) -> Tuple[np.ndarray, np.ndarray]:
        """
        Pr√©pare les features pour l'entra√Ænement des mod√®les ML
        
        Features utilis√©es :
        - Caract√©ristiques de l'√©v√©nement (prix, capacit√©, dur√©e, etc.)
        - Donn√©es temporelles (jour de la semaine, mois, saison)
        - Donn√©es g√©ographiques (ville, pays)
        - Donn√©es de l'organisateur (r√©putation, historique)
        - Donn√©es de cat√©gorie et tags
        """
        features = []
        targets = []
        
        for event in event_data:
            # Features de base
            price = float(event.get('price', 0))
            max_capacity = int(event.get('max_capacity', 10))
            duration_hours = float(event.get('duration_hours', 2))
            organizer_events_count = int(event.get('organizer_events_count', 0))
            organizer_avg_rating = float(event.get('organizer_avg_rating', 0))
            days_until_event = int(event.get('days_until_event', 0))
            category_popularity = int(event.get('category_popularity', 5))
            tags_count = int(event.get('tags_count', 0))
            
            feature_vector = [
                price, max_capacity, duration_hours, organizer_events_count,
                organizer_avg_rating, days_until_event, category_popularity, tags_count
            ]
            
            # Features temporelles
            if event.get('start_date') and hasattr(event['start_date'], 'weekday'):
                start_date = event['start_date']
                weekday = start_date.weekday()
                month = start_date.month
                hour = start_date.hour
                winter = int(month in [12, 1, 2])
                spring = int(month in [3, 4, 5])
                summer = int(month in [6, 7, 8])
                autumn = int(month in [9, 10, 11])
                feature_vector.extend([weekday, month, hour, winter, spring, summer, autumn])
            else:
                # Valeurs par d√©faut pour ao√ªt (√©t√©)
                feature_vector.extend([0, 8, 12, 0, 0, 1, 0])
            
            # Features g√©ographiques (encodage simple mais s√©curis√©)
            city = str(event.get('city', '')).strip()
            country = str(event.get('country', '')).strip()
            category = str(event.get('category', '')).strip()
            
            city_encoding = abs(hash(city)) % 1000 if city else 0
            country_encoding = abs(hash(country)) % 100 if country else 0
            category_encoding = abs(hash(category)) % 50 if category else 0
            
            feature_vector.extend([city_encoding, country_encoding, category_encoding])
            
            # Features de prix relatif
            avg_price_similar_events = float(event.get('avg_price_similar_events', price))
            price_ratio = price / max(avg_price_similar_events, 1.0) if avg_price_similar_events > 0 else 1.0
            feature_vector.append(price_ratio)
            
            # Target : taux de remplissage (0-1)
            fill_rate = event.get('fill_rate', 0)
            if isinstance(fill_rate, (int, float)):
                # Normaliser le taux de remplissage entre 0 et 1
                if fill_rate > 1:
                    target = min(1.0, fill_rate / max_capacity)  # Si c'est un nombre absolu
                else:
                    target = min(1.0, max(0.0, float(fill_rate)))  # Si c'est d√©j√† un ratio
            else:
                target = 0.0
            
            features.append(feature_vector)
            targets.append(target)
        
        return np.array(features), np.array(targets)
    
    def train_fill_rate_predictor(self, force_retrain: bool = False) -> Dict:
        """
        Entra√Æne le mod√®le de pr√©diction du taux de remplissage
        
        Returns:
            Dict avec m√©triques de performance et statut
        """
        try:
            self.ensure_models_directory()
            model_path = os.path.join(self.models_dir, 'fill_rate_predictor.joblib')
            
            # V√©rifier si le mod√®le existe et est r√©cent
            if not force_retrain and os.path.exists(model_path):
                model_age = timezone.now() - datetime.fromtimestamp(os.path.getmtime(model_path), tz=timezone.utc)
                if model_age.days < 7:  # Retra√Æner si plus d'une semaine
                    logger.info("Mod√®le de pr√©diction de remplissage d√©j√† √† jour")
                    return {'status': 'up_to_date', 'message': 'Mod√®le d√©j√† entra√Æn√© et √† jour'}
            
            # R√©cup√©rer les donn√©es d'entra√Ænement
            from .models import Event, EventRegistration, UserProfile
            
            # √âv√©nements pass√©s avec donn√©es de remplissage
            past_events = Event.objects.filter(
                start_date__lt=timezone.now(),
                status='published'
            ).annotate(
                total_registrations=Count('registrations'),
                fill_rate=F('total_registrations') / F('max_capacity'),
                organizer_events_count=Count('organizer__events_organized'),
                days_until_event=F('start_date') - F('created_at'),
                tags_count=Count('tags')
            ).values(
                'id', 'price', 'max_capacity', 'start_date',
                'location', 'category__name', 'fill_rate',
                'organizer_events_count',
                'days_until_event', 'tags_count'
            )
            
            if len(past_events) < 50:
                return {
                    'status': 'insufficient_data',
                    'message': f'Donn√©es insuffisantes pour l\'entra√Ænement: {len(past_events)} √©v√©nements (minimum: 50)'
                }
            
            # Pr√©paration des features
            event_list = list(past_events)
            
            for i, event in enumerate(event_list):
                # Nettoyage et conversion des donn√©es
                event['duration_hours'] = 2  # Valeur par d√©faut
                event['organizer_avg_rating'] = 0  # Valeur par d√©faut
                
                # Conversion s√©curis√©e de days_until_event
                days_until_event = event.get('days_until_event')
                if isinstance(days_until_event, timedelta):
                    event['days_until_event'] = days_until_event.days
                else:
                    event['days_until_event'] = 0
                
                event['category_popularity'] = 5  # Valeur par d√©faut
                event['tags_count'] = int(event.get('tags_count', 0))
                event['avg_price_similar_events'] = float(event.get('price', 0))  # Utiliser le prix de l'√©v√©nement
                event['city'] = event.get('location', '').split(',')[0] if event.get('location') else ''
                event['country'] = event.get('location', '').split(',')[-1].strip() if event.get('location') else ''
                event['category'] = event.get('category__name', '') or 'Unknown'
                
                # Nettoyage des valeurs None
                if event.get('max_capacity') is None:
                    event['max_capacity'] = 10  # Valeur par d√©faut
                if event.get('fill_rate') is None:
                    event['fill_rate'] = 0.0  # Valeur par d√©faut
            
            X, y = self.prepare_event_features(event_list)
            
            # Division train/test
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # Standardisation des features
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            # Entra√Ænement du mod√®le
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            
            model.fit(X_train_scaled, y_train)
            
            # √âvaluation
            y_pred = model.predict(X_test_scaled)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            # Sauvegarde du mod√®le et du scaler
            model_data = {
                'model': model,
                'scaler': self.scaler,
                'feature_names': [
                    'price', 'max_capacity', 'duration_hours', 'organizer_events_count',
                    'organizer_avg_rating', 'days_until_event', 'category_popularity',
                    'tags_count', 'weekday', 'month', 'hour', 'winter', 'spring',
                    'summer', 'autumn', 'city_encoding', 'country_encoding',
                    'category_encoding', 'price_ratio'
                ]
            }
            
            joblib.dump(model_data, model_path)
            
            logger.info(f"Mod√®le de pr√©diction entra√Æn√© avec succ√®s. MAE: {mae:.4f}, R¬≤: {r2:.4f}")
            
            return {
                'status': 'success',
                'message': 'Mod√®le entra√Æn√© avec succ√®s',
                'metrics': {
                    'mae': round(mae, 4),
                    'r2': round(r2, 4),
                    'training_samples': len(X_train),
                    'test_samples': len(X_test)
                }
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de l'entra√Ænement du mod√®le: {str(e)}")
            return {
                'status': 'error',
                'message': f'Erreur lors de l\'entra√Ænement: {str(e)}'
            }
    
    def predict_event_fill_rate(self, event_data: Dict) -> Dict:
        """
        Pr√©dit le taux de remplissage d'un √©v√©nement
        
        Args:
            event_data: Donn√©es de l'√©v√©nement
            
        Returns:
            Dict avec pr√©diction et confiance
        """
        try:
            self.ensure_models_directory()
            model_path = os.path.join(self.models_dir, 'fill_rate_predictor.joblib')
            
            if not os.path.exists(model_path):
                # Entra√Æner le mod√®le si n√©cessaire
                train_result = self.train_fill_rate_predictor()
                if train_result['status'] != 'success':
                    return {
                        'status': 'error',
                        'message': 'Mod√®le non disponible',
                        'prediction': None,
                        'confidence': 0
                    }
            
            # Charger le mod√®le
            model_data = joblib.load(model_path)
            model = model_data['model']
            scaler = model_data['scaler']
            
            # Pr√©parer les features de l'√©v√©nement
            features, _ = self.prepare_event_features([event_data])
            features_scaled = scaler.transform(features)
            
            # Pr√©diction
            prediction = model.predict(features_scaled)[0]
            prediction = max(0.0, min(1.0, prediction))  # Clamp entre 0 et 1
            
            # Calcul de la confiance (bas√© sur la variance des pr√©dictions des arbres)
            predictions_trees = [tree.predict(features_scaled)[0] for tree in model.estimators_]
            confidence = 1.0 - (np.std(predictions_trees) / max(np.mean(predictions_trees), 0.1))
            confidence = max(0.1, min(1.0, confidence))
            
            return {
                'status': 'success',
                'prediction': round(prediction, 4),
                'confidence': round(confidence, 4),
                'predicted_registrations': int(prediction * event_data.get('max_capacity', 0)),
                'message': f'Pr√©diction: {prediction*100:.1f}% de remplissage'
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction: {str(e)}")
            return {
                'status': 'error',
                'message': f'Erreur lors de la pr√©diction: {str(e)}',
                'prediction': None,
                'confidence': 0
            }
    
    def optimize_event_pricing(self, event_data: Dict, target_fill_rate: float = 0.8) -> Dict:
        """
        Optimise le prix d'un √©v√©nement pour atteindre le taux de remplissage cible
        
        Args:
            event_data: Donn√©es de l'√©v√©nement
            target_fill_rate: Taux de remplissage cible (0-1)
            
        Returns:
            Dict avec prix optimis√© et recommandations
        """
        try:
            current_price = float(event_data.get('price', 0))
            if current_price <= 0:
                return {
                    'status': 'error',
                    'message': 'Prix actuel invalide pour l\'optimisation'
                }
            
            # Analyse de la sensibilit√© au prix
            price_variations = np.linspace(current_price * 0.5, current_price * 2.0, 20)
            predictions = []
            
            for price in price_variations:
                test_data = event_data.copy()
                test_data['price'] = price
                
                # Pr√©dire le taux de remplissage pour ce prix
                prediction_result = self.predict_event_fill_rate(test_data)
                if prediction_result['status'] == 'success':
                    predictions.append({
                        'price': price,
                        'fill_rate': prediction_result['prediction'],
                        'revenue': price * event_data.get('max_capacity', 0) * prediction_result['prediction']
                    })
            
            if not predictions:
                return {
                    'status': 'error',
                    'message': 'Impossible de g√©n√©rer des pr√©dictions de prix'
                }
            
            # Trouver le prix optimal
            predictions_df = pd.DataFrame(predictions)
            
            # Prix pour le taux de remplissage cible
            target_prices = predictions_df[
                predictions_df['fill_rate'] >= target_fill_rate
            ]
            
            if len(target_prices) > 0:
                # Prix optimal bas√© sur le revenu maximum
                optimal_price = target_prices.loc[target_prices['revenue'].idxmax(), 'price']
                optimal_fill_rate = target_prices.loc[target_prices['revenue'].idxmax(), 'fill_rate']
                optimal_revenue = target_prices.loc[target_prices['revenue'].idxmax(), 'revenue']
            else:
                # Si pas de prix atteint le taux cible, prendre le meilleur compromis
                optimal_price = predictions_df.loc[predictions_df['revenue'].idxmax(), 'price']
                optimal_fill_rate = predictions_df.loc[predictions_df['revenue'].idxmax(), 'fill_rate']
                optimal_revenue = predictions_df.loc[predictions_df['revenue'].idxmax(), 'revenue']
            
            # Analyse de la concurrence
            market_analysis = self.analyze_market_competition(event_data)
            
            # Recommandations
            recommendations = []
            if optimal_price < current_price:
                recommendations.append("üí° R√©duire le prix pour augmenter le taux de remplissage")
            elif optimal_price > current_price:
                recommendations.append("üí∞ Augmenter le prix pour maximiser les revenus")
            
            if market_analysis.get('status') == 'success':
                if market_analysis['price_position'] == 'high':
                    recommendations.append("‚ö†Ô∏è Prix plus √©lev√© que la concurrence - risque de faible remplissage")
                elif market_analysis['price_position'] == 'low':
                    recommendations.append("‚úÖ Prix comp√©titif par rapport √† la concurrence")
            
            return {
                'status': 'success',
                'current_price': current_price,
                'optimal_price': round(optimal_price, 2),
                'price_change_percent': round(((optimal_price - current_price) / current_price) * 100, 1),
                'target_fill_rate': target_fill_rate,
                'predicted_fill_rate': round(optimal_fill_rate, 4),
                'predicted_revenue': round(optimal_revenue, 2),
                'revenue_improvement': round(((optimal_revenue - (current_price * event_data.get('max_capacity', 0) * 0.5)) / (current_price * event_data.get('max_capacity', 0) * 0.5)) * 100, 1),
                'market_analysis': market_analysis,
                'recommendations': recommendations
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de l'optimisation des prix: {str(e)}")
            return {
                'status': 'error',
                'message': f'Erreur lors de l\'optimisation: {str(e)}'
            }
    
    def analyze_market_competition(self, event_data: Dict) -> Dict:
        """
        Analyse la concurrence sur le march√© pour un √©v√©nement
        
        Args:
            event_data: Donn√©es de l'√©v√©nement
            
        Returns:
            Dict avec analyse de la concurrence
        """
        try:
            from .models import Event
            
            # √âv√©nements similaires (m√™me cat√©gorie, p√©riode proche)
            similar_events = Event.objects.filter(
                category__name=event_data.get('category'),
                start_date__gte=timezone.now() - timedelta(days=30),
                start_date__lte=timezone.now() + timedelta(days=90),
                status='published'
            ).exclude(id=event_data.get('id')).values('price', 'max_capacity')
            
            if not similar_events:
                return {
                    'status': 'success',
                    'competition_level': 'low',
                    'price_position': 'unknown',
                    'avg_market_price': 0,
                    'price_percentile': 50
                }
            
            # Statistiques de prix
            prices = [float(event['price']) for event in similar_events]
            avg_market_price = np.mean(prices)
            current_price = float(event_data.get('price', 0))
            
            # Position de prix
            if current_price < avg_market_price * 0.8:
                price_position = 'low'
            elif current_price > avg_market_price * 1.2:
                price_position = 'high'
            else:
                price_position = 'competitive'
            
            # Percentile de prix
            price_percentile = np.percentile(prices, current_price)
            
            # Niveau de concurrence
            competition_level = 'high' if len(similar_events) > 10 else 'medium' if len(similar_events) > 5 else 'low'
            
            return {
                'status': 'success',
                'competition_level': competition_level,
                'price_position': price_position,
                'avg_market_price': round(avg_market_price, 2),
                'price_percentile': round(price_percentile, 1),
                'similar_events_count': len(similar_events),
                'price_range': {
                    'min': round(min(prices), 2),
                    'max': round(max(prices), 2)
                }
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse de la concurrence: {str(e)}")
            return {
                'status': 'error',
                'competition_level': 'unknown',
                'price_position': 'unknown',
                'avg_market_price': 0,
                'price_percentile': 50
            }
    
    def detect_emerging_trends(self, days_back: int = 90) -> Dict:
        """
        D√©tecte les tendances √©mergentes dans les √©v√©nements
        
        Args:
            days_back: Nombre de jours √† analyser
            
        Returns:
            Dict avec tendances d√©tect√©es
        """
        try:
            from .models import Event, EventRegistration, Category, Tag
            
            end_date = timezone.now()
            start_date = end_date - timedelta(days=days_back)
            
            # Tendances par cat√©gorie - CORRIG√â avec distinct=True
            category_trends = Category.objects.annotate(
                recent_events=Count('event', filter=Q(event__created_at__gte=start_date), distinct=True),
                total_events=Count('event', distinct=True),
                recent_registrations=Count('event__registrations', filter=Q(event__registrations__registered_at__gte=start_date), distinct=True),
                avg_price=Avg('event__price'),
                avg_fill_rate=Avg('event__registrations') / F('event__max_capacity')
            ).filter(recent_events__gt=0).order_by('-recent_events')[:10]
            
            # Tendances par tags - CORRIG√â avec distinct=True
            tag_trends = Tag.objects.annotate(
                recent_usage=Count('event', filter=Q(event__created_at__gte=start_date), distinct=True),
                total_usage=Count('event', distinct=True),
                growth_rate=(F('recent_usage') * 100.0) / F('total_usage')
            ).filter(recent_usage__gt=0).order_by('-growth_rate')[:10]
            
            # Tendances temporelles
            temporal_trends = []
            for i in range(0, days_back, 7):  # Par semaine
                week_start = start_date + timedelta(days=i)
                week_end = week_start + timedelta(days=7)
                
                week_events = Event.objects.filter(
                    created_at__gte=week_start,
                    created_at__lt=week_end
                ).count()
                
                week_registrations = EventRegistration.objects.filter(
                    registered_at__gte=week_start,
                    registered_at__lt=week_end
                ).count()
                
                temporal_trends.append({
                    'week': week_start.strftime('%Y-%m-%d'),
                    'events_created': week_events,
                    'registrations': week_registrations
                })
            
            # Tendances de prix
            price_trends = Event.objects.filter(
                created_at__gte=start_date
            ).aggregate(
                avg_price=Avg('price'),
                min_price=Min('price'),
                max_price=Max('price'),
                price_std=StdDev('price')
            )
            
            # D√©tection de tendances √©mergentes
            emerging_trends = []
            
            # Cat√©gories en forte croissance
            for category in category_trends:
                if category.recent_events > 0 and category.total_events > 0:
                    growth_rate = (category.recent_events / category.total_events) * 100
                    if growth_rate > 20:  # Croissance > 20%
                        emerging_trends.append({
                            'type': 'category_growth',
                            'name': category.name,
                            'growth_rate': round(growth_rate, 1),
                            'recent_events': category.recent_events,
                            'avg_price': round(float(category.avg_price or 0), 2),
                            'avg_fill_rate': round(float(category.avg_fill_rate or 0), 4)
                        })
            
            # Tags √©mergents
            for tag in tag_trends:
                if tag.growth_rate > 30:  # Croissance > 30%
                    emerging_trends.append({
                        'type': 'tag_emerging',
                        'name': tag.name,
                        'growth_rate': round(tag.growth_rate, 1),
                        'recent_usage': tag.recent_usage,
                        'total_usage': tag.total_usage
                    })
            
            # Tendances de prix
            if price_trends['avg_price']:
                price_trends_clean = {
                    'avg_price': round(float(price_trends['avg_price']), 2),
                    'min_price': round(float(price_trends['min_price'] or 0), 2),
                    'max_price': round(float(price_trends['max_price'] or 0), 2),
                    'price_volatility': round(float(price_trends['price_std'] or 0), 2)
                }
            else:
                price_trends_clean = {}
            
            return {
                'status': 'success',
                'analysis_period': f'{days_back} jours',
                'emerging_trends': emerging_trends,
                'category_trends': self.validate_category_data(category_trends),
                'tag_trends': [
                    {
                        'name': tag.name,
                        'recent_usage': tag.recent_usage,
                        'total_usage': tag.total_usage,
                        'growth_rate': round(tag.growth_rate, 1)
                    }
                    for tag in tag_trends
                ],
                'temporal_trends': temporal_trends,
                'price_trends': price_trends_clean,
                'insights': self._generate_trend_insights(emerging_trends, category_trends, tag_trends)
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de la d√©tection des tendances: {str(e)}")
            return {
                'status': 'error',
                'message': f'Erreur lors de la d√©tection des tendances: {str(e)}'
            }
    
    def _generate_trend_insights(self, emerging_trends: List, category_trends: List, tag_trends: List) -> List[str]:
        """G√©n√®re des insights bas√©s sur les tendances d√©tect√©es"""
        insights = []
        
        # Insights sur les cat√©gories
        if category_trends:
            top_category = category_trends[0]
            insights.append(f"üî• {top_category.name} est la cat√©gorie la plus active avec {top_category.recent_events} √©v√©nements r√©cents")
        
        # Insights sur les tags
        if tag_trends:
            top_tag = tag_trends[0]
            insights.append(f"üöÄ Le tag '{top_tag.name}' conna√Æt une croissance de {top_tag.growth_rate:.1f}%")
        
        # Insights sur les tendances √©mergentes
        if emerging_trends:
            category_trends_count = len([t for t in emerging_trends if t['type'] == 'category_growth'])
            tag_trends_count = len([t for t in emerging_trends if t['type'] == 'tag_emerging'])
            
            if category_trends_count > 0:
                insights.append(f"üìà {category_trends_count} cat√©gorie(s) en forte croissance d√©tect√©e(s)")
            
            if tag_trends_count > 0:
                insights.append(f"üè∑Ô∏è {tag_trends_count} tag(s) √©mergent(s) identifi√©(s)")
        
        return insights
    
    def get_predictive_insights(self, event_id: int = None) -> Dict:
        """
        G√©n√®re des insights pr√©dictifs globaux ou pour un √©v√©nement sp√©cifique
        
        Args:
            event_id: ID de l'√©v√©nement (optionnel)
            
        Returns:
            Dict avec insights pr√©dictifs
        """
        try:
            
            insights = {
                'status': 'success',
                'timestamp': timezone.now().isoformat(),
                'global_insights': [],
                'event_specific_insights': [],
                'recommendations': []
            }
            
            # Insights globaux
            trends = self.detect_emerging_trends()
            
            if trends['status'] == 'success':
                insights['global_insights'].extend(trends['insights'])
                
                # Recommandations bas√©es sur les tendances
                if trends['category_trends']:
                    top_category = trends['category_trends'][0]
                    insights['recommendations'].append(
                        f"üí° Concentrez-vous sur la cat√©gorie '{top_category['name']}' qui conna√Æt une croissance de {top_category['growth_rate']}%"
                    )
                
                if trends['tag_trends']:
                    top_tag = trends['tag_trends'][0]
                    insights['recommendations'].append(
                        f"üè∑Ô∏è Utilisez le tag '{top_tag['name']}' pour am√©liorer la visibilit√© de vos √©v√©nements"
                    )
            
            # Insights sp√©cifiques √† un √©v√©nement
            if event_id:
                from .models import Event
                try:
                    event = Event.objects.get(id=event_id)
                    
                    event_data = {
                        'id': event.id,
                        'price': float(event.price),
                        'max_capacity': event.max_capacity or 100,
                        'category': event.category.name if event.category else '',
                        'city': event.location.split(',')[0] if event.location else '',
                        'country': event.location.split(',')[-1].strip() if event.location else '',
                        'start_date': event.start_date,
                        'duration_hours': 2,
                        'organizer_events_count': event.organizer.events_organized.count() if event.organizer else 0,
                        'organizer_avg_rating': getattr(event.organizer.profile, 'rating', 0) if event.organizer and hasattr(event.organizer, 'profile') else 0,
                        'tags_count': event.tags.count()
                    }
                    
                    # Pr√©diction de remplissage
                    fill_prediction = self.predict_event_fill_rate(event_data)
                    
                    if fill_prediction['status'] == 'success':
                        insights['event_specific_insights'].append(
                            f"üéØ Taux de remplissage pr√©dit: {fill_prediction['prediction']*100:.1f}% (confiance: {fill_prediction['confidence']*100:.1f}%)"
                        )
                    
                    # Optimisation des prix
                    price_optimization = self.optimize_event_pricing(event_data)
                    
                    if price_optimization['status'] == 'success':
                        insights['event_specific_insights'].append(
                            f"üí∞ Prix optimal sugg√©r√©: {price_optimization['optimal_price']}‚Ç¨ (changement: {price_optimization['price_change_percent']}%)"
                        )
                        
                        if price_optimization['recommendations']:
                            insights['recommendations'].extend(price_optimization['recommendations'])
                    
                    # Analyse de la concurrence
                    market_analysis = self.analyze_market_competition(event_data)
                    
                    if market_analysis.get('status') == 'success' and market_analysis.get('competition_level') != 'unknown':
                        insights['event_specific_insights'].append(
                            f"üèÜ Niveau de concurrence: {market_analysis['competition_level']} (prix: {market_analysis['price_position']})"
                        )
                
                except Event.DoesNotExist:
                    insights['event_specific_insights'].append("‚ùå √âv√©nement non trouv√©")
            return insights
            
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration des insights: {str(e)}")
            return {
                'status': 'error',
                'message': f'Erreur lors de la g√©n√©ration des insights: {str(e)}'
            }

    def validate_category_data(self, category_trends: List) -> List:
        """
        Valide et corrige les donn√©es des cat√©gories pour √©viter les anomalies
        """
        validated_trends = []
        
        for cat in category_trends:
            # V√©rifier que les comptages sont raisonnables
            recent_events = min(cat.recent_events, 1000) if cat.recent_events else 0
            total_events = min(cat.total_events, 1000) if cat.total_events else 0
            
            # S'assurer que recent_events <= total_events
            if recent_events > total_events:
                recent_events = total_events
            
            # Calculer le taux de croissance de mani√®re s√©curis√©e
            if total_events > 0:
                growth_rate = (recent_events / total_events) * 100
            else:
                growth_rate = 0.0
            
            validated_trends.append({
                'name': cat.name,
                'recent_events': recent_events,
                'total_events': total_events,
                'growth_rate': round(growth_rate, 1),
                'avg_price': round(float(cat.avg_price or 0), 2),
                'avg_fill_rate': round(float(cat.avg_fill_rate or 0), 4)
            })
        
        return validated_trends

def get_predictive_service():
    """Retourne une instance du service d'analytics pr√©dictifs"""
    return PredictiveAnalyticsService()

# Instance globale du service (pour compatibilit√©)
predictive_service = None
